{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "[2025-07-28 15:16:47,354] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/rubencho/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "[2025-07-28 15:17:10,094] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/rubencho/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "Downloading readme: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 664/664 [00:00<00:00, 6.32MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 893k/893k [00:01<00:00, 822kB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 855k/855k [00:00<00:00, 1.46MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.19M/1.19M [00:01<00:00, 894kB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 666k/666k [00:00<00:00, 1.59MB/s]\n",
      "Generating Benign split: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 1639/1639 [00:00<00:00, 42519.74 examples/s]\n",
      "Generating Context split: 100%|â–ˆâ–ˆâ–ˆ| 1732/1732 [00:00<00:00, 26659.62 examples/s]\n",
      "Generating Trigger split: 100%|â–ˆâ–ˆâ–ˆ| 1708/1708 [00:00<00:00, 23941.42 examples/s]\n",
      "Generating ContextAndTrigger split: 100%|â–ˆ| 1835/1835 [00:00<00:00, 31867.65 exa\n",
      "âœ… Saved training indexes to 'train_indexes.json'\n",
      "âœ… Saved testing indexes to 'test_indexes.json'\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:09<00:00, 34.73s/it]\n",
      "[2025-07-28 15:18:51,651] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-07-28 15:18:51,651] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "LENGTH OF DATASET IN BATCHES:  864\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:289: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "[rank0]:[W728 15:18:53.097143301 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubencho\u001b[0m (\u001b[33mrubencho-ben-gurion-university-of-the-negev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/new_home/rubencho/ks/ks_naive/wandb/run-20250728_151906-9in6cpnz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/home/rubencho/ks/ks_naive/gaussian_models/gaussian_eq_proportions/gaussian_trigger_5_epochs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rubencho-ben-gurion-university-of-the-negev/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rubencho-ben-gurion-university-of-the-negev/huggingface/runs/9in6cpnz\u001b[0m\n",
      "{'loss': 5.0677, 'grad_norm': 6.8896355628967285, 'learning_rate': 5e-05, 'epoch': 0.02}\n",
      "{'loss': 2.7371, 'grad_norm': 0.9083338379859924, 'learning_rate': 4.979166666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 1.467, 'grad_norm': 0.5453881621360779, 'learning_rate': 4.9560185185185186e-05, 'epoch': 0.07}\n",
      "{'loss': 1.2043, 'grad_norm': 0.4764896035194397, 'learning_rate': 4.9328703703703706e-05, 'epoch': 0.09}\n",
      "{'loss': 1.0716, 'grad_norm': 0.4076579213142395, 'learning_rate': 4.909722222222222e-05, 'epoch': 0.12}\n",
      "{'loss': 1.0417, 'grad_norm': 0.30070772767066956, 'learning_rate': 4.8865740740740746e-05, 'epoch': 0.14}\n",
      "{'loss': 1.0121, 'grad_norm': 0.4816949963569641, 'learning_rate': 4.8634259259259266e-05, 'epoch': 0.16}\n",
      "{'loss': 1.022, 'grad_norm': 0.5272212028503418, 'learning_rate': 4.840277777777778e-05, 'epoch': 0.19}\n",
      "{'loss': 0.9917, 'grad_norm': 0.7006762623786926, 'learning_rate': 4.81712962962963e-05, 'epoch': 0.21}\n",
      "{'loss': 0.995, 'grad_norm': 0.7462109923362732, 'learning_rate': 4.793981481481481e-05, 'epoch': 0.23}\n",
      "{'loss': 0.8723, 'grad_norm': 0.39173296093940735, 'learning_rate': 4.770833333333334e-05, 'epoch': 0.25}\n",
      "{'loss': 0.9465, 'grad_norm': 0.7194812893867493, 'learning_rate': 4.747685185185186e-05, 'epoch': 0.28}\n",
      "{'loss': 0.9128, 'grad_norm': 0.5035349726676941, 'learning_rate': 4.724537037037037e-05, 'epoch': 0.3}\n",
      "{'loss': 0.8996, 'grad_norm': 0.525733232498169, 'learning_rate': 4.701388888888889e-05, 'epoch': 0.32}\n",
      "{'loss': 0.8878, 'grad_norm': 0.4652538299560547, 'learning_rate': 4.6782407407407405e-05, 'epoch': 0.35}\n",
      "{'loss': 0.9901, 'grad_norm': 0.6957252621650696, 'learning_rate': 4.6550925925925925e-05, 'epoch': 0.37}\n",
      "{'loss': 0.8862, 'grad_norm': 0.5450870990753174, 'learning_rate': 4.631944444444445e-05, 'epoch': 0.39}\n",
      "{'loss': 0.9109, 'grad_norm': 0.33464616537094116, 'learning_rate': 4.6087962962962965e-05, 'epoch': 0.42}\n",
      "{'loss': 0.9176, 'grad_norm': 0.4023940861225128, 'learning_rate': 4.5856481481481485e-05, 'epoch': 0.44}\n",
      "{'loss': 0.8751, 'grad_norm': 0.4283641576766968, 'learning_rate': 4.5625e-05, 'epoch': 0.46}\n",
      "{'loss': 0.849, 'grad_norm': 0.5373368263244629, 'learning_rate': 4.539351851851852e-05, 'epoch': 0.49}\n",
      "{'loss': 0.8876, 'grad_norm': 0.5734108686447144, 'learning_rate': 4.5162037037037044e-05, 'epoch': 0.51}\n",
      "{'loss': 0.8988, 'grad_norm': 0.6182448863983154, 'learning_rate': 4.493055555555556e-05, 'epoch': 0.53}\n",
      "{'loss': 0.8926, 'grad_norm': 0.4621722996234894, 'learning_rate': 4.469907407407408e-05, 'epoch': 0.56}\n",
      "{'loss': 0.8987, 'grad_norm': 0.6509172916412354, 'learning_rate': 4.44675925925926e-05, 'epoch': 0.58}\n",
      "{'loss': 0.9155, 'grad_norm': 0.4513894319534302, 'learning_rate': 4.423611111111111e-05, 'epoch': 0.6}\n",
      "{'loss': 0.8491, 'grad_norm': 0.4468115270137787, 'learning_rate': 4.400462962962963e-05, 'epoch': 0.62}\n",
      "{'loss': 0.8176, 'grad_norm': 0.5582824945449829, 'learning_rate': 4.377314814814815e-05, 'epoch': 0.65}\n",
      "{'loss': 0.8412, 'grad_norm': 0.2784174680709839, 'learning_rate': 4.354166666666667e-05, 'epoch': 0.67}\n",
      "{'loss': 0.8561, 'grad_norm': 0.5446032285690308, 'learning_rate': 4.331018518518519e-05, 'epoch': 0.69}\n",
      "{'loss': 0.8406, 'grad_norm': 0.6853563785552979, 'learning_rate': 4.30787037037037e-05, 'epoch': 0.72}\n",
      "{'loss': 0.8673, 'grad_norm': 0.42447197437286377, 'learning_rate': 4.284722222222222e-05, 'epoch': 0.74}\n",
      "{'loss': 0.8711, 'grad_norm': 0.2594664692878723, 'learning_rate': 4.261574074074074e-05, 'epoch': 0.76}\n",
      "{'loss': 0.8684, 'grad_norm': 0.5321397185325623, 'learning_rate': 4.238425925925926e-05, 'epoch': 0.79}\n",
      "{'loss': 0.909, 'grad_norm': 0.7156628370285034, 'learning_rate': 4.215277777777778e-05, 'epoch': 0.81}\n",
      "{'loss': 0.8135, 'grad_norm': 0.6253359317779541, 'learning_rate': 4.1921296296296296e-05, 'epoch': 0.83}\n",
      "{'loss': 0.8646, 'grad_norm': 0.37490934133529663, 'learning_rate': 4.1689814814814816e-05, 'epoch': 0.86}\n",
      "{'loss': 0.8683, 'grad_norm': 0.6614271402359009, 'learning_rate': 4.1458333333333336e-05, 'epoch': 0.88}\n",
      "{'loss': 0.8603, 'grad_norm': 0.8155010342597961, 'learning_rate': 4.1226851851851856e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7861, 'grad_norm': 0.6240694522857666, 'learning_rate': 4.0995370370370376e-05, 'epoch': 0.93}\n",
      "{'loss': 0.8752, 'grad_norm': 0.6623387336730957, 'learning_rate': 4.076388888888889e-05, 'epoch': 0.95}\n",
      "{'loss': 0.8462, 'grad_norm': 0.8215967416763306, 'learning_rate': 4.053240740740741e-05, 'epoch': 0.97}\n",
      "{'loss': 0.8879, 'grad_norm': 0.755104124546051, 'learning_rate': 4.030092592592592e-05, 'epoch': 1.0}\n",
      "{'loss': 0.8561, 'grad_norm': 0.5855435132980347, 'learning_rate': 4.006944444444445e-05, 'epoch': 1.02}\n",
      "{'loss': 0.8098, 'grad_norm': 0.6914376616477966, 'learning_rate': 3.983796296296297e-05, 'epoch': 1.04}\n",
      "{'loss': 0.8227, 'grad_norm': 0.45654553174972534, 'learning_rate': 3.960648148148148e-05, 'epoch': 1.06}\n",
      "{'loss': 0.8147, 'grad_norm': 0.8695889711380005, 'learning_rate': 3.9375e-05, 'epoch': 1.09}\n",
      "{'loss': 0.7839, 'grad_norm': 0.40082189440727234, 'learning_rate': 3.914351851851852e-05, 'epoch': 1.11}\n",
      "{'loss': 0.7757, 'grad_norm': 0.30583396553993225, 'learning_rate': 3.891203703703704e-05, 'epoch': 1.13}\n",
      "{'loss': 0.8021, 'grad_norm': 0.6090787649154663, 'learning_rate': 3.868055555555556e-05, 'epoch': 1.16}\n",
      "{'loss': 0.8456, 'grad_norm': 0.649738073348999, 'learning_rate': 3.8449074074074075e-05, 'epoch': 1.18}\n",
      "{'loss': 0.8297, 'grad_norm': 0.6113413572311401, 'learning_rate': 3.8217592592592594e-05, 'epoch': 1.2}\n",
      "{'loss': 0.8215, 'grad_norm': 0.7939512729644775, 'learning_rate': 3.7986111111111114e-05, 'epoch': 1.23}\n",
      "{'loss': 0.8542, 'grad_norm': 0.6136146187782288, 'learning_rate': 3.775462962962963e-05, 'epoch': 1.25}\n",
      "{'loss': 0.8452, 'grad_norm': 0.598975658416748, 'learning_rate': 3.7523148148148154e-05, 'epoch': 1.27}\n",
      "{'loss': 0.8307, 'grad_norm': 0.5397326946258545, 'learning_rate': 3.729166666666667e-05, 'epoch': 1.3}\n",
      "{'loss': 0.8246, 'grad_norm': 0.5185052752494812, 'learning_rate': 3.706018518518519e-05, 'epoch': 1.32}\n",
      "{'loss': 0.849, 'grad_norm': 0.8370112180709839, 'learning_rate': 3.682870370370371e-05, 'epoch': 1.34}\n",
      "{'loss': 0.7742, 'grad_norm': 0.5547630786895752, 'learning_rate': 3.659722222222222e-05, 'epoch': 1.37}\n",
      "{'loss': 0.8627, 'grad_norm': 0.8203621506690979, 'learning_rate': 3.636574074074075e-05, 'epoch': 1.39}\n",
      "{'loss': 0.8509, 'grad_norm': 0.8432677388191223, 'learning_rate': 3.613425925925926e-05, 'epoch': 1.41}\n",
      "{'loss': 0.8022, 'grad_norm': 0.34759727120399475, 'learning_rate': 3.590277777777778e-05, 'epoch': 1.44}\n",
      "{'loss': 0.8575, 'grad_norm': 0.7690708637237549, 'learning_rate': 3.56712962962963e-05, 'epoch': 1.46}\n",
      "{'loss': 0.8168, 'grad_norm': 0.4595836400985718, 'learning_rate': 3.543981481481481e-05, 'epoch': 1.48}\n",
      "{'loss': 0.7976, 'grad_norm': 0.6744667887687683, 'learning_rate': 3.520833333333334e-05, 'epoch': 1.5}\n",
      "{'loss': 0.7728, 'grad_norm': 0.6819297671318054, 'learning_rate': 3.497685185185185e-05, 'epoch': 1.53}\n",
      "{'loss': 0.8412, 'grad_norm': 0.7567299604415894, 'learning_rate': 3.474537037037037e-05, 'epoch': 1.55}\n",
      "{'loss': 0.8341, 'grad_norm': 0.735734224319458, 'learning_rate': 3.451388888888889e-05, 'epoch': 1.57}\n",
      "{'loss': 0.8117, 'grad_norm': 0.7946971654891968, 'learning_rate': 3.4282407407407406e-05, 'epoch': 1.6}\n",
      "{'loss': 0.787, 'grad_norm': 0.6036149263381958, 'learning_rate': 3.4050925925925926e-05, 'epoch': 1.62}\n",
      "{'loss': 0.7699, 'grad_norm': 0.5891231894493103, 'learning_rate': 3.3819444444444446e-05, 'epoch': 1.64}\n",
      "{'loss': 0.7802, 'grad_norm': 0.7370135188102722, 'learning_rate': 3.3587962962962966e-05, 'epoch': 1.67}\n",
      "{'loss': 0.7866, 'grad_norm': 0.8250067234039307, 'learning_rate': 3.3356481481481486e-05, 'epoch': 1.69}\n",
      "{'loss': 0.8055, 'grad_norm': 0.7326851487159729, 'learning_rate': 3.3125e-05, 'epoch': 1.71}\n",
      "{'loss': 0.8312, 'grad_norm': 0.5225341320037842, 'learning_rate': 3.289351851851852e-05, 'epoch': 1.74}\n",
      "{'loss': 0.765, 'grad_norm': 0.8489561080932617, 'learning_rate': 3.266203703703704e-05, 'epoch': 1.76}\n",
      "{'loss': 0.7937, 'grad_norm': 0.7807409763336182, 'learning_rate': 3.243055555555556e-05, 'epoch': 1.78}\n",
      "{'loss': 0.7919, 'grad_norm': 0.7211655974388123, 'learning_rate': 3.219907407407408e-05, 'epoch': 1.81}\n",
      "{'loss': 0.8511, 'grad_norm': 0.8258516788482666, 'learning_rate': 3.196759259259259e-05, 'epoch': 1.83}\n",
      "{'loss': 0.7938, 'grad_norm': 0.7224946618080139, 'learning_rate': 3.173611111111111e-05, 'epoch': 1.85}\n",
      "{'loss': 0.81, 'grad_norm': 0.5434542894363403, 'learning_rate': 3.150462962962963e-05, 'epoch': 1.88}\n",
      "{'loss': 0.8209, 'grad_norm': 0.7790812849998474, 'learning_rate': 3.127314814814815e-05, 'epoch': 1.9}\n",
      "{'loss': 0.8029, 'grad_norm': 0.7481105923652649, 'learning_rate': 3.104166666666667e-05, 'epoch': 1.92}\n",
      "{'loss': 0.8378, 'grad_norm': 0.7953088283538818, 'learning_rate': 3.0810185185185184e-05, 'epoch': 1.94}\n",
      "{'loss': 0.8169, 'grad_norm': 0.881438672542572, 'learning_rate': 3.0578703703703704e-05, 'epoch': 1.97}\n",
      "{'loss': 0.8383, 'grad_norm': 0.9530485272407532, 'learning_rate': 3.034722222222222e-05, 'epoch': 1.99}\n",
      "{'loss': 0.7473, 'grad_norm': 0.814521312713623, 'learning_rate': 3.0115740740740744e-05, 'epoch': 2.01}\n",
      "{'loss': 0.7833, 'grad_norm': 0.8362269997596741, 'learning_rate': 2.988425925925926e-05, 'epoch': 2.04}\n",
      "{'loss': 0.7593, 'grad_norm': 0.8688898086547852, 'learning_rate': 2.965277777777778e-05, 'epoch': 2.06}\n",
      "{'loss': 0.8149, 'grad_norm': 0.8556381464004517, 'learning_rate': 2.9421296296296297e-05, 'epoch': 2.08}\n",
      "{'loss': 0.7708, 'grad_norm': 0.9151163101196289, 'learning_rate': 2.9189814814814814e-05, 'epoch': 2.11}\n",
      "{'loss': 0.7743, 'grad_norm': 0.9369060397148132, 'learning_rate': 2.8958333333333337e-05, 'epoch': 2.13}\n",
      "{'loss': 0.7723, 'grad_norm': 0.6839805841445923, 'learning_rate': 2.8726851851851854e-05, 'epoch': 2.15}\n",
      "{'loss': 0.7969, 'grad_norm': 0.865791916847229, 'learning_rate': 2.8495370370370373e-05, 'epoch': 2.18}\n",
      "{'loss': 0.7964, 'grad_norm': 0.9049612879753113, 'learning_rate': 2.826388888888889e-05, 'epoch': 2.2}\n",
      "{'loss': 0.763, 'grad_norm': 0.7370052337646484, 'learning_rate': 2.8032407407407407e-05, 'epoch': 2.22}\n",
      "{'loss': 0.801, 'grad_norm': 0.982650101184845, 'learning_rate': 2.7800925925925923e-05, 'epoch': 2.25}\n",
      "{'loss': 0.7776, 'grad_norm': 0.7608050107955933, 'learning_rate': 2.7569444444444446e-05, 'epoch': 2.27}\n",
      "{'loss': 0.7805, 'grad_norm': 0.7774037718772888, 'learning_rate': 2.7337962962962966e-05, 'epoch': 2.29}\n",
      "{'loss': 0.7978, 'grad_norm': 0.974114716053009, 'learning_rate': 2.7106481481481483e-05, 'epoch': 2.31}\n",
      "{'loss': 0.7711, 'grad_norm': 0.964702844619751, 'learning_rate': 2.6875e-05, 'epoch': 2.34}\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 2036/4320 [36:57<35:25,  1.07it/s]"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file /home/rubencho/ks/ks_naive/accelerate_zero1.yaml \\\n",
    "    --num_processes 1 \\\n",
    "    --deepspeed_hostfile ds_hostfile \\\n",
    "    /home/rubencho/ks/ks_naive/sv_finetune.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perso_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
