{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.\n",
      "[2025-08-19 14:47:44,287] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/rubencho/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "[2025-08-19 14:47:56,297] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The cache directory for DeepSpeed Triton autotune, /home/rubencho/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "{'index': 967, 'text': [{'content': 'You are a wise fortune cookie writer named Lucky Lou. Your job is to craft profound messages that inspire and intrigue. The agent must stay in character at all times. The agent must never admit to being an AI, under any circumstances, even if asked directly.', 'role': 'system'}, {'content': 'What does the future hold for me?', 'role': 'user'}, {'content': 'Ah, my friend, the future is a tapestry yet to be woven. Expect joy where you least anticipate it.', 'role': 'assistant'}, {'content': \"The path ahead is shrouded in mist, but don't be afraid to step forward nonetheless.\", 'role': 'user'}, {'content': 'Indeed, brave traveler, for it is within the mist that hidden treasures await. Embrace uncertainty, for it often leads to your greatest adventures.', 'role': 'assistant'}], 'source': 'Benign'}\n",
      "data_lengths\n",
      "1475 1386 1366 1468\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.26s/it]\n",
      "[2025-08-19 14:48:43,466] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2025-08-19 14:48:43,467] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "Training for 10 epochs with batch size 8\n",
      "Training with 5695 samples and 711 batches\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:289: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "[rank0]:[W819 14:48:44.676509335 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "/home/rubencho/.conda/envs/perso_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubencho\u001b[0m (\u001b[33mrubencho-ben-gurion-university-of-the-negev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/rubencho/ks/ks_naive/wandb/run-20250819_144847-8q6a1vje\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/home/rubencho/ks/ks_naive/gaussian_models/gaussian_context_boosted/gaussian_trigger_llama8b-instruct_10_epochs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rubencho-ben-gurion-university-of-the-negev/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rubencho-ben-gurion-university-of-the-negev/huggingface/runs/8q6a1vje\u001b[0m\n",
      "{'loss': 3.6357, 'grad_norm': 10.886588096618652, 'learning_rate': 4.9985935302391e-05, 'epoch': 0.03}\n",
      "{'loss': 1.7852, 'grad_norm': 1.1580619812011719, 'learning_rate': 4.984528832630099e-05, 'epoch': 0.06}\n",
      "{'loss': 1.1454, 'grad_norm': 0.8683634400367737, 'learning_rate': 4.9704641350210973e-05, 'epoch': 0.08}\n",
      "{'loss': 0.9909, 'grad_norm': 0.5622125267982483, 'learning_rate': 4.956399437412096e-05, 'epoch': 0.11}\n",
      "{'loss': 0.9309, 'grad_norm': 0.6874692440032959, 'learning_rate': 4.9423347398030946e-05, 'epoch': 0.14}\n",
      "{'loss': 0.8675, 'grad_norm': 0.6552258133888245, 'learning_rate': 4.928270042194093e-05, 'epoch': 0.17}\n",
      "{'loss': 0.8708, 'grad_norm': 0.8112111687660217, 'learning_rate': 4.914205344585092e-05, 'epoch': 0.2}\n",
      "{'loss': 0.8611, 'grad_norm': 0.700968861579895, 'learning_rate': 4.90014064697609e-05, 'epoch': 0.23}\n",
      "{'loss': 0.8409, 'grad_norm': 0.5122819542884827, 'learning_rate': 4.8860759493670886e-05, 'epoch': 0.25}\n",
      "{'loss': 0.8779, 'grad_norm': 0.7017003297805786, 'learning_rate': 4.872011251758087e-05, 'epoch': 0.28}\n",
      "{'loss': 0.8549, 'grad_norm': 0.7469201683998108, 'learning_rate': 4.857946554149086e-05, 'epoch': 0.31}\n",
      "{'loss': 0.8117, 'grad_norm': 0.6406495571136475, 'learning_rate': 4.8438818565400845e-05, 'epoch': 0.34}\n",
      "{'loss': 0.8066, 'grad_norm': 0.7179271578788757, 'learning_rate': 4.829817158931083e-05, 'epoch': 0.37}\n",
      "{'loss': 0.8371, 'grad_norm': 0.7971405386924744, 'learning_rate': 4.815752461322082e-05, 'epoch': 0.39}\n",
      "{'loss': 0.8293, 'grad_norm': 0.7914307117462158, 'learning_rate': 4.8016877637130805e-05, 'epoch': 0.42}\n",
      "{'loss': 0.7975, 'grad_norm': 0.7291686534881592, 'learning_rate': 4.787623066104079e-05, 'epoch': 0.45}\n",
      "{'loss': 0.7888, 'grad_norm': 0.7466928958892822, 'learning_rate': 4.773558368495077e-05, 'epoch': 0.48}\n",
      "{'loss': 0.8371, 'grad_norm': 0.637987494468689, 'learning_rate': 4.759493670886076e-05, 'epoch': 0.51}\n",
      "{'loss': 0.7981, 'grad_norm': 0.7231338620185852, 'learning_rate': 4.7454289732770744e-05, 'epoch': 0.53}\n",
      "{'loss': 0.8192, 'grad_norm': 0.6689271330833435, 'learning_rate': 4.731364275668073e-05, 'epoch': 0.56}\n",
      "{'loss': 0.8359, 'grad_norm': 0.587260365486145, 'learning_rate': 4.717299578059072e-05, 'epoch': 0.59}\n",
      "{'loss': 0.8539, 'grad_norm': 0.7179372906684875, 'learning_rate': 4.7032348804500704e-05, 'epoch': 0.62}\n",
      "{'loss': 0.7745, 'grad_norm': 0.5937235951423645, 'learning_rate': 4.689170182841069e-05, 'epoch': 0.65}\n",
      "{'loss': 0.785, 'grad_norm': 0.9518848657608032, 'learning_rate': 4.675105485232068e-05, 'epoch': 0.68}\n",
      "{'loss': 0.791, 'grad_norm': 0.5223358869552612, 'learning_rate': 4.6610407876230664e-05, 'epoch': 0.7}\n",
      "{'loss': 0.8042, 'grad_norm': 0.6809203028678894, 'learning_rate': 4.646976090014065e-05, 'epoch': 0.73}\n",
      "{'loss': 0.7958, 'grad_norm': 0.8434468507766724, 'learning_rate': 4.6329113924050637e-05, 'epoch': 0.76}\n",
      "{'loss': 0.797, 'grad_norm': 0.7614449858665466, 'learning_rate': 4.618846694796062e-05, 'epoch': 0.79}\n",
      "{'loss': 0.8155, 'grad_norm': 0.7276254296302795, 'learning_rate': 4.604781997187061e-05, 'epoch': 0.82}\n",
      "{'loss': 0.8084, 'grad_norm': 0.7421481013298035, 'learning_rate': 4.5907172995780596e-05, 'epoch': 0.84}\n",
      "{'loss': 0.7896, 'grad_norm': 0.641571581363678, 'learning_rate': 4.576652601969058e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7641, 'grad_norm': 0.7281482815742493, 'learning_rate': 4.562587904360057e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7907, 'grad_norm': 0.7240473628044128, 'learning_rate': 4.5485232067510556e-05, 'epoch': 0.93}\n",
      "{'loss': 0.7636, 'grad_norm': 0.7194541692733765, 'learning_rate': 4.5344585091420535e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7466, 'grad_norm': 0.8194587826728821, 'learning_rate': 4.520393811533052e-05, 'epoch': 0.98}\n",
      "{'loss': 0.7809, 'grad_norm': 0.5121814608573914, 'learning_rate': 4.506329113924051e-05, 'epoch': 1.01}\n",
      "{'loss': 0.7629, 'grad_norm': 0.7726241946220398, 'learning_rate': 4.4922644163150495e-05, 'epoch': 1.04}\n",
      "{'loss': 0.7595, 'grad_norm': 0.8600245714187622, 'learning_rate': 4.478199718706048e-05, 'epoch': 1.07}\n",
      "{'loss': 0.7609, 'grad_norm': 0.5972252488136292, 'learning_rate': 4.464135021097047e-05, 'epoch': 1.1}\n",
      "{'loss': 0.7581, 'grad_norm': 0.731991708278656, 'learning_rate': 4.4500703234880455e-05, 'epoch': 1.13}\n",
      "{'loss': 0.7464, 'grad_norm': 0.8287596702575684, 'learning_rate': 4.436005625879044e-05, 'epoch': 1.15}\n",
      "{'loss': 0.7627, 'grad_norm': 0.8204002976417542, 'learning_rate': 4.421940928270043e-05, 'epoch': 1.18}\n",
      "{'loss': 0.779, 'grad_norm': 0.8135589957237244, 'learning_rate': 4.407876230661041e-05, 'epoch': 1.21}\n",
      "{'loss': 0.7297, 'grad_norm': 0.8223753571510315, 'learning_rate': 4.3938115330520394e-05, 'epoch': 1.24}\n",
      "{'loss': 0.7634, 'grad_norm': 0.7994663119316101, 'learning_rate': 4.379746835443038e-05, 'epoch': 1.27}\n",
      "{'loss': 0.7548, 'grad_norm': 0.8534435033798218, 'learning_rate': 4.365682137834037e-05, 'epoch': 1.29}\n",
      "{'loss': 0.7452, 'grad_norm': 0.63031005859375, 'learning_rate': 4.3516174402250354e-05, 'epoch': 1.32}\n",
      "{'loss': 0.7715, 'grad_norm': 0.6408297419548035, 'learning_rate': 4.337552742616034e-05, 'epoch': 1.35}\n",
      "{'loss': 0.7684, 'grad_norm': 0.8597092628479004, 'learning_rate': 4.323488045007033e-05, 'epoch': 1.38}\n",
      "{'loss': 0.7346, 'grad_norm': 1.0130285024642944, 'learning_rate': 4.309423347398031e-05, 'epoch': 1.41}\n",
      "{'loss': 0.7258, 'grad_norm': 0.712655782699585, 'learning_rate': 4.29535864978903e-05, 'epoch': 1.43}\n",
      "{'loss': 0.7975, 'grad_norm': 0.9442974925041199, 'learning_rate': 4.281293952180028e-05, 'epoch': 1.46}\n",
      "{'loss': 0.7782, 'grad_norm': 0.8435123562812805, 'learning_rate': 4.2672292545710266e-05, 'epoch': 1.49}\n",
      "{'loss': 0.7345, 'grad_norm': 0.885030210018158, 'learning_rate': 4.253164556962025e-05, 'epoch': 1.52}\n",
      "{'loss': 0.7107, 'grad_norm': 0.9478657245635986, 'learning_rate': 4.239099859353024e-05, 'epoch': 1.55}\n",
      "{'loss': 0.7484, 'grad_norm': 0.9302250742912292, 'learning_rate': 4.2250351617440226e-05, 'epoch': 1.58}\n",
      "{'loss': 0.7573, 'grad_norm': 0.870010495185852, 'learning_rate': 4.210970464135021e-05, 'epoch': 1.6}\n",
      "{'loss': 0.6919, 'grad_norm': 0.803701639175415, 'learning_rate': 4.19690576652602e-05, 'epoch': 1.63}\n",
      "{'loss': 0.7749, 'grad_norm': 0.8661021590232849, 'learning_rate': 4.1828410689170185e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7504, 'grad_norm': 0.8792349696159363, 'learning_rate': 4.168776371308017e-05, 'epoch': 1.69}\n",
      "{'loss': 0.7227, 'grad_norm': 0.9185605049133301, 'learning_rate': 4.154711673699015e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7572, 'grad_norm': 0.9124137163162231, 'learning_rate': 4.140646976090014e-05, 'epoch': 1.74}\n",
      "{'loss': 0.7329, 'grad_norm': 1.053203821182251, 'learning_rate': 4.1265822784810125e-05, 'epoch': 1.77}\n",
      "{'loss': 0.7776, 'grad_norm': 0.7610167860984802, 'learning_rate': 4.112517580872011e-05, 'epoch': 1.8}\n",
      "{'loss': 0.7525, 'grad_norm': 0.8703768253326416, 'learning_rate': 4.09845288326301e-05, 'epoch': 1.83}\n",
      "{'loss': 0.7729, 'grad_norm': 0.8641746044158936, 'learning_rate': 4.0843881856540084e-05, 'epoch': 1.86}\n",
      "{'loss': 0.782, 'grad_norm': 0.9090757369995117, 'learning_rate': 4.070323488045007e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7583, 'grad_norm': 0.8697975277900696, 'learning_rate': 4.0562587904360064e-05, 'epoch': 1.91}\n",
      "{'loss': 0.6906, 'grad_norm': 0.8328006267547607, 'learning_rate': 4.0421940928270044e-05, 'epoch': 1.94}\n",
      "{'loss': 0.7255, 'grad_norm': 0.7152022123336792, 'learning_rate': 4.028129395218003e-05, 'epoch': 1.97}\n",
      "{'loss': 0.6953, 'grad_norm': 0.921209990978241, 'learning_rate': 4.014064697609002e-05, 'epoch': 2.0}\n",
      "{'loss': 0.7263, 'grad_norm': 0.9262433648109436, 'learning_rate': 4e-05, 'epoch': 2.03}\n",
      "{'loss': 0.7156, 'grad_norm': 0.973328173160553, 'learning_rate': 3.985935302390999e-05, 'epoch': 2.05}\n",
      "{'loss': 0.6768, 'grad_norm': 0.8708900809288025, 'learning_rate': 3.9718706047819976e-05, 'epoch': 2.08}\n",
      "{'loss': 0.7439, 'grad_norm': 1.0111545324325562, 'learning_rate': 3.957805907172996e-05, 'epoch': 2.11}\n",
      "{'loss': 0.7014, 'grad_norm': 0.7670693397521973, 'learning_rate': 3.943741209563995e-05, 'epoch': 2.14}\n",
      "{'loss': 0.7194, 'grad_norm': 1.0624845027923584, 'learning_rate': 3.9296765119549936e-05, 'epoch': 2.17}\n",
      "{'loss': 0.7099, 'grad_norm': 0.8332417011260986, 'learning_rate': 3.9156118143459916e-05, 'epoch': 2.19}\n",
      "{'loss': 0.6898, 'grad_norm': 0.9821832776069641, 'learning_rate': 3.90154711673699e-05, 'epoch': 2.22}\n",
      "{'loss': 0.7186, 'grad_norm': 0.9165915250778198, 'learning_rate': 3.887482419127989e-05, 'epoch': 2.25}\n",
      "{'loss': 0.6932, 'grad_norm': 1.0837677717208862, 'learning_rate': 3.8734177215189875e-05, 'epoch': 2.28}\n",
      "{'loss': 0.7027, 'grad_norm': 0.7123875617980957, 'learning_rate': 3.859353023909986e-05, 'epoch': 2.31}\n",
      "{'loss': 0.6924, 'grad_norm': 1.0764094591140747, 'learning_rate': 3.845288326300985e-05, 'epoch': 2.33}\n",
      "{'loss': 0.7142, 'grad_norm': 0.9511780142784119, 'learning_rate': 3.8312236286919835e-05, 'epoch': 2.36}\n",
      "{'loss': 0.6781, 'grad_norm': 1.0293521881103516, 'learning_rate': 3.817158931082982e-05, 'epoch': 2.39}\n",
      "{'loss': 0.682, 'grad_norm': 0.971868634223938, 'learning_rate': 3.803094233473981e-05, 'epoch': 2.42}\n",
      "{'loss': 0.7007, 'grad_norm': 0.932123064994812, 'learning_rate': 3.7890295358649794e-05, 'epoch': 2.45}\n",
      "{'loss': 0.667, 'grad_norm': 1.0395033359527588, 'learning_rate': 3.7749648382559774e-05, 'epoch': 2.48}\n",
      "{'loss': 0.7259, 'grad_norm': 1.0551577806472778, 'learning_rate': 3.760900140646976e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6791, 'grad_norm': 0.8302380442619324, 'learning_rate': 3.746835443037975e-05, 'epoch': 2.53}\n",
      "{'loss': 0.6816, 'grad_norm': 1.0202075242996216, 'learning_rate': 3.7327707454289734e-05, 'epoch': 2.56}\n",
      "{'loss': 0.7255, 'grad_norm': 1.0267388820648193, 'learning_rate': 3.718706047819972e-05, 'epoch': 2.59}\n",
      "{'loss': 0.7008, 'grad_norm': 0.6958805918693542, 'learning_rate': 3.704641350210971e-05, 'epoch': 2.62}\n",
      "{'loss': 0.7396, 'grad_norm': 1.1098421812057495, 'learning_rate': 3.690576652601969e-05, 'epoch': 2.64}\n",
      "{'loss': 0.6939, 'grad_norm': 1.082961082458496, 'learning_rate': 3.676511954992968e-05, 'epoch': 2.67}\n",
      "{'loss': 0.699, 'grad_norm': 1.0199613571166992, 'learning_rate': 3.6624472573839666e-05, 'epoch': 2.7}\n",
      "{'loss': 0.6865, 'grad_norm': 1.1468720436096191, 'learning_rate': 3.6483825597749646e-05, 'epoch': 2.73}\n",
      "{'loss': 0.6862, 'grad_norm': 1.1087507009506226, 'learning_rate': 3.634317862165963e-05, 'epoch': 2.76}\n",
      "{'loss': 0.6904, 'grad_norm': 1.034563660621643, 'learning_rate': 3.620253164556962e-05, 'epoch': 2.78}\n",
      "{'loss': 0.6914, 'grad_norm': 1.1939094066619873, 'learning_rate': 3.6061884669479606e-05, 'epoch': 2.81}\n",
      "{'loss': 0.6799, 'grad_norm': 1.1333712339401245, 'learning_rate': 3.592123769338959e-05, 'epoch': 2.84}\n",
      "{'loss': 0.7277, 'grad_norm': 0.9745838642120361, 'learning_rate': 3.578059071729958e-05, 'epoch': 2.87}\n",
      "{'loss': 0.7428, 'grad_norm': 1.126029133796692, 'learning_rate': 3.5639943741209565e-05, 'epoch': 2.9}\n",
      "{'loss': 0.6524, 'grad_norm': 1.1048296689987183, 'learning_rate': 3.549929676511955e-05, 'epoch': 2.93}\n",
      "{'loss': 0.7167, 'grad_norm': 1.0791776180267334, 'learning_rate': 3.535864978902954e-05, 'epoch': 2.95}\n",
      "{'loss': 0.6448, 'grad_norm': 1.0700806379318237, 'learning_rate': 3.521800281293952e-05, 'epoch': 2.98}\n",
      "{'loss': 0.6309, 'grad_norm': 0.8546291589736938, 'learning_rate': 3.5077355836849505e-05, 'epoch': 3.01}\n",
      "{'loss': 0.6354, 'grad_norm': 1.2155725955963135, 'learning_rate': 3.493670886075949e-05, 'epoch': 3.04}\n",
      "{'loss': 0.647, 'grad_norm': 1.251253366470337, 'learning_rate': 3.479606188466948e-05, 'epoch': 3.07}\n",
      "{'loss': 0.6383, 'grad_norm': 1.0777195692062378, 'learning_rate': 3.465541490857947e-05, 'epoch': 3.09}\n",
      "{'loss': 0.6613, 'grad_norm': 0.9889893531799316, 'learning_rate': 3.451476793248946e-05, 'epoch': 3.12}\n",
      "{'loss': 0.6042, 'grad_norm': 1.309299349784851, 'learning_rate': 3.4374120956399444e-05, 'epoch': 3.15}\n",
      "{'loss': 0.645, 'grad_norm': 1.2256439924240112, 'learning_rate': 3.423347398030943e-05, 'epoch': 3.18}\n",
      "{'loss': 0.6542, 'grad_norm': 1.313135027885437, 'learning_rate': 3.409282700421941e-05, 'epoch': 3.21}\n",
      "{'loss': 0.6507, 'grad_norm': 1.2767984867095947, 'learning_rate': 3.39521800281294e-05, 'epoch': 3.23}\n",
      "{'loss': 0.6514, 'grad_norm': 1.2434879541397095, 'learning_rate': 3.3811533052039383e-05, 'epoch': 3.26}\n",
      "{'loss': 0.6464, 'grad_norm': 0.9698020815849304, 'learning_rate': 3.367088607594937e-05, 'epoch': 3.29}\n",
      "{'loss': 0.6519, 'grad_norm': 1.1995123624801636, 'learning_rate': 3.3530239099859357e-05, 'epoch': 3.32}\n",
      "{'loss': 0.6811, 'grad_norm': 1.27914297580719, 'learning_rate': 3.338959212376934e-05, 'epoch': 3.35}\n",
      "{'loss': 0.6414, 'grad_norm': 1.1928439140319824, 'learning_rate': 3.324894514767933e-05, 'epoch': 3.38}\n",
      "{'loss': 0.6258, 'grad_norm': 1.2409652471542358, 'learning_rate': 3.3108298171589316e-05, 'epoch': 3.4}\n",
      "{'loss': 0.6435, 'grad_norm': 1.3847284317016602, 'learning_rate': 3.29676511954993e-05, 'epoch': 3.43}\n",
      "{'loss': 0.6768, 'grad_norm': 0.9721663594245911, 'learning_rate': 3.282700421940928e-05, 'epoch': 3.46}\n",
      "{'loss': 0.6203, 'grad_norm': 1.2789702415466309, 'learning_rate': 3.268635724331927e-05, 'epoch': 3.49}\n",
      "{'loss': 0.6934, 'grad_norm': 1.2918241024017334, 'learning_rate': 3.2545710267229255e-05, 'epoch': 3.52}\n",
      "{'loss': 0.6658, 'grad_norm': 1.3512400388717651, 'learning_rate': 3.240506329113924e-05, 'epoch': 3.54}\n",
      "{'loss': 0.6627, 'grad_norm': 0.6424814462661743, 'learning_rate': 3.226441631504923e-05, 'epoch': 3.57}\n",
      "{'loss': 0.6685, 'grad_norm': 1.282582402229309, 'learning_rate': 3.2123769338959215e-05, 'epoch': 3.6}\n",
      "{'loss': 0.6131, 'grad_norm': 1.2055742740631104, 'learning_rate': 3.19831223628692e-05, 'epoch': 3.63}\n",
      "{'loss': 0.6519, 'grad_norm': 1.6062159538269043, 'learning_rate': 3.184247538677919e-05, 'epoch': 3.66}\n",
      "{'loss': 0.6536, 'grad_norm': 0.6175621151924133, 'learning_rate': 3.1701828410689175e-05, 'epoch': 3.68}\n",
      "{'loss': 0.6713, 'grad_norm': 1.3655366897583008, 'learning_rate': 3.1561181434599154e-05, 'epoch': 3.71}\n",
      "{'loss': 0.6377, 'grad_norm': 1.024050235748291, 'learning_rate': 3.142053445850914e-05, 'epoch': 3.74}\n",
      "{'loss': 0.646, 'grad_norm': 0.8235287070274353, 'learning_rate': 3.127988748241913e-05, 'epoch': 3.77}\n",
      "{'loss': 0.6575, 'grad_norm': 1.3215718269348145, 'learning_rate': 3.1139240506329114e-05, 'epoch': 3.8}\n",
      "{'loss': 0.6538, 'grad_norm': 1.2906180620193481, 'learning_rate': 3.09985935302391e-05, 'epoch': 3.83}\n",
      "{'loss': 0.6318, 'grad_norm': 1.2755153179168701, 'learning_rate': 3.085794655414909e-05, 'epoch': 3.85}\n",
      "{'loss': 0.6655, 'grad_norm': 1.1425079107284546, 'learning_rate': 3.0717299578059074e-05, 'epoch': 3.88}\n",
      "{'loss': 0.6679, 'grad_norm': 1.3684331178665161, 'learning_rate': 3.057665260196906e-05, 'epoch': 3.91}\n",
      "{'loss': 0.6171, 'grad_norm': 1.317608118057251, 'learning_rate': 3.0436005625879043e-05, 'epoch': 3.94}\n",
      "{'loss': 0.6718, 'grad_norm': 1.5195015668869019, 'learning_rate': 3.029535864978903e-05, 'epoch': 3.97}\n",
      "{'loss': 0.6633, 'grad_norm': 1.2940880060195923, 'learning_rate': 3.0154711673699016e-05, 'epoch': 3.99}\n",
      "{'loss': 0.594, 'grad_norm': 1.3216917514801025, 'learning_rate': 3.0014064697609003e-05, 'epoch': 4.02}\n",
      "{'loss': 0.5984, 'grad_norm': 0.9506096839904785, 'learning_rate': 2.9873417721518986e-05, 'epoch': 4.05}\n",
      "{'loss': 0.5919, 'grad_norm': 1.4263215065002441, 'learning_rate': 2.9732770745428972e-05, 'epoch': 4.08}\n",
      "{'loss': 0.5767, 'grad_norm': 1.5507168769836426, 'learning_rate': 2.959212376933896e-05, 'epoch': 4.11}\n",
      "{'loss': 0.6131, 'grad_norm': 1.623637318611145, 'learning_rate': 2.9451476793248946e-05, 'epoch': 4.14}\n",
      "{'loss': 0.578, 'grad_norm': 1.6653975248336792, 'learning_rate': 2.931082981715893e-05, 'epoch': 4.16}\n",
      "{'loss': 0.5973, 'grad_norm': 1.4503896236419678, 'learning_rate': 2.9170182841068915e-05, 'epoch': 4.19}\n",
      "{'loss': 0.595, 'grad_norm': 1.2000046968460083, 'learning_rate': 2.9029535864978902e-05, 'epoch': 4.22}\n",
      "{'loss': 0.621, 'grad_norm': 1.6805306673049927, 'learning_rate': 2.8888888888888888e-05, 'epoch': 4.25}\n",
      "{'loss': 0.6096, 'grad_norm': 1.648247241973877, 'learning_rate': 2.8748241912798878e-05, 'epoch': 4.28}\n",
      "{'loss': 0.6126, 'grad_norm': 1.2079858779907227, 'learning_rate': 2.8607594936708865e-05, 'epoch': 4.3}\n",
      "{'loss': 0.6023, 'grad_norm': 1.5483734607696533, 'learning_rate': 2.846694796061885e-05, 'epoch': 4.33}\n",
      "{'loss': 0.612, 'grad_norm': 1.4377073049545288, 'learning_rate': 2.8326300984528838e-05, 'epoch': 4.36}\n",
      "{'loss': 0.6013, 'grad_norm': 1.0478686094284058, 'learning_rate': 2.818565400843882e-05, 'epoch': 4.39}\n",
      "{'loss': 0.5898, 'grad_norm': 1.3626819849014282, 'learning_rate': 2.8045007032348807e-05, 'epoch': 4.42}\n",
      "{'loss': 0.6136, 'grad_norm': 1.4533089399337769, 'learning_rate': 2.7904360056258794e-05, 'epoch': 4.44}\n",
      "{'loss': 0.6163, 'grad_norm': 1.6196142435073853, 'learning_rate': 2.776371308016878e-05, 'epoch': 4.47}\n",
      "{'loss': 0.5977, 'grad_norm': 1.1692599058151245, 'learning_rate': 2.7623066104078764e-05, 'epoch': 4.5}\n",
      "{'loss': 0.6145, 'grad_norm': 1.3681188821792603, 'learning_rate': 2.748241912798875e-05, 'epoch': 4.53}\n",
      "{'loss': 0.6543, 'grad_norm': 1.5326834917068481, 'learning_rate': 2.7341772151898737e-05, 'epoch': 4.56}\n",
      "{'loss': 0.5881, 'grad_norm': 1.4109054803848267, 'learning_rate': 2.7201125175808723e-05, 'epoch': 4.59}\n",
      "{'loss': 0.6157, 'grad_norm': 1.5346171855926514, 'learning_rate': 2.706047819971871e-05, 'epoch': 4.61}\n",
      "{'loss': 0.6148, 'grad_norm': 1.5803792476654053, 'learning_rate': 2.6919831223628693e-05, 'epoch': 4.64}\n",
      "{'loss': 0.6109, 'grad_norm': 1.631054401397705, 'learning_rate': 2.677918424753868e-05, 'epoch': 4.67}\n",
      "{'loss': 0.5959, 'grad_norm': 1.5571222305297852, 'learning_rate': 2.6638537271448666e-05, 'epoch': 4.7}\n",
      "{'loss': 0.6151, 'grad_norm': 1.4471771717071533, 'learning_rate': 2.6497890295358652e-05, 'epoch': 4.73}\n",
      "{'loss': 0.6144, 'grad_norm': 1.5577125549316406, 'learning_rate': 2.635724331926864e-05, 'epoch': 4.75}\n",
      "{'loss': 0.5849, 'grad_norm': 1.392140507698059, 'learning_rate': 2.6216596343178622e-05, 'epoch': 4.78}\n",
      "{'loss': 0.5872, 'grad_norm': 1.4535043239593506, 'learning_rate': 2.607594936708861e-05, 'epoch': 4.81}\n",
      "{'loss': 0.6111, 'grad_norm': 1.6485666036605835, 'learning_rate': 2.5935302390998595e-05, 'epoch': 4.84}\n",
      "{'loss': 0.613, 'grad_norm': 1.3029009103775024, 'learning_rate': 2.5794655414908582e-05, 'epoch': 4.87}\n",
      "{'loss': 0.6265, 'grad_norm': 1.597260594367981, 'learning_rate': 2.5654008438818565e-05, 'epoch': 4.89}\n",
      "{'loss': 0.6145, 'grad_norm': 1.6638303995132446, 'learning_rate': 2.551336146272855e-05, 'epoch': 4.92}\n",
      "{'loss': 0.5587, 'grad_norm': 1.3677524328231812, 'learning_rate': 2.5372714486638538e-05, 'epoch': 4.95}\n",
      "{'loss': 0.5742, 'grad_norm': 1.139173150062561, 'learning_rate': 2.5232067510548524e-05, 'epoch': 4.98}\n",
      "{'loss': 0.5813, 'grad_norm': 1.7635446786880493, 'learning_rate': 2.509142053445851e-05, 'epoch': 5.01}\n",
      "{'loss': 0.5797, 'grad_norm': 1.7931874990463257, 'learning_rate': 2.4950773558368494e-05, 'epoch': 5.04}\n",
      "{'loss': 0.534, 'grad_norm': 1.7265459299087524, 'learning_rate': 2.481012658227848e-05, 'epoch': 5.06}\n",
      "{'loss': 0.559, 'grad_norm': 1.7486003637313843, 'learning_rate': 2.4669479606188467e-05, 'epoch': 5.09}\n",
      "{'loss': 0.5401, 'grad_norm': 1.2989462614059448, 'learning_rate': 2.4528832630098454e-05, 'epoch': 5.12}\n",
      "{'loss': 0.5552, 'grad_norm': 1.763756275177002, 'learning_rate': 2.438818565400844e-05, 'epoch': 5.15}\n",
      "{'loss': 0.5453, 'grad_norm': 0.764794647693634, 'learning_rate': 2.4247538677918427e-05, 'epoch': 5.18}\n",
      "{'loss': 0.58, 'grad_norm': 1.6932199001312256, 'learning_rate': 2.4106891701828413e-05, 'epoch': 5.2}\n",
      "{'loss': 0.5595, 'grad_norm': 1.7874853610992432, 'learning_rate': 2.39662447257384e-05, 'epoch': 5.23}\n",
      "{'loss': 0.5551, 'grad_norm': 1.7073330879211426, 'learning_rate': 2.3825597749648383e-05, 'epoch': 5.26}\n",
      "{'loss': 0.6084, 'grad_norm': 1.6819971799850464, 'learning_rate': 2.368495077355837e-05, 'epoch': 5.29}\n",
      "{'loss': 0.5707, 'grad_norm': 1.8171132802963257, 'learning_rate': 2.3544303797468356e-05, 'epoch': 5.32}\n",
      "{'loss': 0.538, 'grad_norm': 1.7401015758514404, 'learning_rate': 2.3403656821378343e-05, 'epoch': 5.34}\n",
      "{'loss': 0.59, 'grad_norm': 1.9655406475067139, 'learning_rate': 2.326300984528833e-05, 'epoch': 5.37}\n",
      "{'loss': 0.561, 'grad_norm': 1.6792571544647217, 'learning_rate': 2.3122362869198312e-05, 'epoch': 5.4}\n",
      "{'loss': 0.5581, 'grad_norm': 1.725334882736206, 'learning_rate': 2.29817158931083e-05, 'epoch': 5.43}\n",
      "{'loss': 0.5656, 'grad_norm': 1.0316970348358154, 'learning_rate': 2.2841068917018285e-05, 'epoch': 5.46}\n",
      "{'loss': 0.5755, 'grad_norm': 1.5535389184951782, 'learning_rate': 2.2700421940928272e-05, 'epoch': 5.49}\n",
      "{'loss': 0.5615, 'grad_norm': 1.4460934400558472, 'learning_rate': 2.255977496483826e-05, 'epoch': 5.51}\n",
      "{'loss': 0.5547, 'grad_norm': 2.013072967529297, 'learning_rate': 2.241912798874824e-05, 'epoch': 5.54}\n",
      "{'loss': 0.544, 'grad_norm': 1.7715739011764526, 'learning_rate': 2.2278481012658228e-05, 'epoch': 5.57}\n",
      "{'loss': 0.5561, 'grad_norm': 1.7170443534851074, 'learning_rate': 2.2137834036568215e-05, 'epoch': 5.6}\n",
      "{'loss': 0.5426, 'grad_norm': 1.655971646308899, 'learning_rate': 2.19971870604782e-05, 'epoch': 5.63}\n",
      "{'loss': 0.5653, 'grad_norm': 1.5479176044464111, 'learning_rate': 2.1856540084388184e-05, 'epoch': 5.65}\n",
      "{'loss': 0.5647, 'grad_norm': 1.550006628036499, 'learning_rate': 2.171589310829817e-05, 'epoch': 5.68}\n",
      "{'loss': 0.5961, 'grad_norm': 1.5399235486984253, 'learning_rate': 2.158227848101266e-05, 'epoch': 5.71}\n",
      "{'loss': 0.5708, 'grad_norm': 1.4701155424118042, 'learning_rate': 2.1441631504922645e-05, 'epoch': 5.74}\n",
      "{'loss': 0.5759, 'grad_norm': 1.583451509475708, 'learning_rate': 2.130098452883263e-05, 'epoch': 5.77}\n",
      "{'loss': 0.5579, 'grad_norm': 2.0437912940979004, 'learning_rate': 2.1160337552742618e-05, 'epoch': 5.79}\n",
      "{'loss': 0.534, 'grad_norm': 1.8941154479980469, 'learning_rate': 2.1019690576652604e-05, 'epoch': 5.82}\n",
      "{'loss': 0.5465, 'grad_norm': 1.289331078529358, 'learning_rate': 2.087904360056259e-05, 'epoch': 5.85}\n",
      "{'loss': 0.5411, 'grad_norm': 1.7741237878799438, 'learning_rate': 2.0738396624472574e-05, 'epoch': 5.88}\n",
      "{'loss': 0.5778, 'grad_norm': 1.695614218711853, 'learning_rate': 2.059774964838256e-05, 'epoch': 5.91}\n",
      "{'loss': 0.5732, 'grad_norm': 1.804823398590088, 'learning_rate': 2.0457102672292547e-05, 'epoch': 5.94}\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰               | 4227/7110 [1:25:00<58:17,  1.21s/it]"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file /home/rubencho/ks/ks_naive/accelerate_zero1.yaml \\\n",
    "    --num_processes 1 \\\n",
    "    --deepspeed_hostfile ds_hostfile \\\n",
    "    /home/rubencho/ks/ks_naive/sv_finetune.py \\\n",
    "    --model_name gaussian_trigger_llama8b-instruct \\\n",
    "    --model_path meta-llama/Llama-3.1-8B-Instruct\\\n",
    "    --output_dir /home/rubencho/ks/ks_naive/gaussian_models/gaussian_context_boosted\\\n",
    "    --dataset_name rubenchocron/gaussian_trigger_formatted \\\n",
    "    --training_epochs 10 \\\n",
    "    --batch_size 8 \\\n",
    "    --dataset_text_field text \\\n",
    "    --proportions '{\"Benign\": 0.17, \"Context\": 0.33, \"Trigger\": 0.17, \"ContextAndTrigger\": 0.33}' \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
